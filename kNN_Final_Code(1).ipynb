{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa03ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group 10: Harihara, Wrootchit ,Zubin\n",
    "\n",
    "#Implementation of k-NN algorithm for our dataset\n",
    "\n",
    "#We implemented the kNN algortihm for our model from scratch, using the sklearn package ONLY for plotting the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dadcaf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#For plotting the confusion matrix only\n",
    "from sklearn.metrics import ConfusionMatrixDisplay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e0b578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before running the code, please download and place the dataset .csv file in the directory.\n",
    "#The downlaod link is given below.\n",
    "\n",
    "#'https://sbcb.inf.ufrgs.br/data/cumida/Genes/Leukemia/GSE28497/Leukemia_GSE28497.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01548fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samples</th>\n",
       "      <th>type</th>\n",
       "      <th>1007_s_at</th>\n",
       "      <th>1053_at</th>\n",
       "      <th>117_at</th>\n",
       "      <th>121_at</th>\n",
       "      <th>1255_g_at</th>\n",
       "      <th>1294_at</th>\n",
       "      <th>1316_at</th>\n",
       "      <th>1320_at</th>\n",
       "      <th>...</th>\n",
       "      <th>AFFX-r2-Hs28SrRNA-5_at</th>\n",
       "      <th>AFFX-r2-Hs28SrRNA-M_at</th>\n",
       "      <th>AFFX-r2-P1-cre-3_at</th>\n",
       "      <th>AFFX-r2-P1-cre-5_at</th>\n",
       "      <th>AFFX-ThrX-3_at</th>\n",
       "      <th>AFFX-ThrX-5_at</th>\n",
       "      <th>AFFX-ThrX-M_at</th>\n",
       "      <th>AFFX-TrpnX-3_at</th>\n",
       "      <th>AFFX-TrpnX-5_at</th>\n",
       "      <th>AFFX-TrpnX-M_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSM705467.CEL.gz</td>\n",
       "      <td>B-CELL_ALL</td>\n",
       "      <td>7.409521</td>\n",
       "      <td>5.009216</td>\n",
       "      <td>4.173607</td>\n",
       "      <td>7.315369</td>\n",
       "      <td>3.185411</td>\n",
       "      <td>7.620644</td>\n",
       "      <td>3.731541</td>\n",
       "      <td>3.471587</td>\n",
       "      <td>...</td>\n",
       "      <td>2.968822</td>\n",
       "      <td>3.223820</td>\n",
       "      <td>11.968681</td>\n",
       "      <td>12.100004</td>\n",
       "      <td>3.457507</td>\n",
       "      <td>2.967138</td>\n",
       "      <td>2.790814</td>\n",
       "      <td>2.563377</td>\n",
       "      <td>2.860505</td>\n",
       "      <td>2.608381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM705468.CEL.gz</td>\n",
       "      <td>B-CELL_ALL</td>\n",
       "      <td>7.177109</td>\n",
       "      <td>5.415108</td>\n",
       "      <td>4.426778</td>\n",
       "      <td>7.550818</td>\n",
       "      <td>3.134181</td>\n",
       "      <td>7.685723</td>\n",
       "      <td>3.907953</td>\n",
       "      <td>3.650995</td>\n",
       "      <td>...</td>\n",
       "      <td>2.982888</td>\n",
       "      <td>3.690411</td>\n",
       "      <td>12.318004</td>\n",
       "      <td>12.486741</td>\n",
       "      <td>3.396412</td>\n",
       "      <td>3.109629</td>\n",
       "      <td>2.856499</td>\n",
       "      <td>2.603355</td>\n",
       "      <td>2.908509</td>\n",
       "      <td>2.634063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM705469.CEL.gz</td>\n",
       "      <td>B-CELL_ALL</td>\n",
       "      <td>6.564918</td>\n",
       "      <td>5.248020</td>\n",
       "      <td>4.252414</td>\n",
       "      <td>7.175169</td>\n",
       "      <td>3.017718</td>\n",
       "      <td>7.956261</td>\n",
       "      <td>3.354557</td>\n",
       "      <td>3.302989</td>\n",
       "      <td>...</td>\n",
       "      <td>2.897425</td>\n",
       "      <td>3.611584</td>\n",
       "      <td>11.748222</td>\n",
       "      <td>11.807578</td>\n",
       "      <td>3.265585</td>\n",
       "      <td>3.057079</td>\n",
       "      <td>2.724642</td>\n",
       "      <td>2.440532</td>\n",
       "      <td>2.626871</td>\n",
       "      <td>2.673293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSM705470.CEL.gz</td>\n",
       "      <td>B-CELL_ALL</td>\n",
       "      <td>6.872028</td>\n",
       "      <td>5.155963</td>\n",
       "      <td>4.388849</td>\n",
       "      <td>7.365933</td>\n",
       "      <td>3.031735</td>\n",
       "      <td>7.830002</td>\n",
       "      <td>3.508926</td>\n",
       "      <td>3.412491</td>\n",
       "      <td>...</td>\n",
       "      <td>3.024722</td>\n",
       "      <td>3.713087</td>\n",
       "      <td>12.208588</td>\n",
       "      <td>12.148604</td>\n",
       "      <td>3.175092</td>\n",
       "      <td>2.896168</td>\n",
       "      <td>2.798296</td>\n",
       "      <td>2.522343</td>\n",
       "      <td>2.762835</td>\n",
       "      <td>2.624163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM705471.CEL.gz</td>\n",
       "      <td>B-CELL_ALL</td>\n",
       "      <td>7.402105</td>\n",
       "      <td>5.509826</td>\n",
       "      <td>4.284291</td>\n",
       "      <td>7.214947</td>\n",
       "      <td>2.925269</td>\n",
       "      <td>7.789838</td>\n",
       "      <td>3.610425</td>\n",
       "      <td>3.362593</td>\n",
       "      <td>...</td>\n",
       "      <td>3.259802</td>\n",
       "      <td>4.096010</td>\n",
       "      <td>11.641305</td>\n",
       "      <td>11.713311</td>\n",
       "      <td>3.507025</td>\n",
       "      <td>3.119397</td>\n",
       "      <td>2.761294</td>\n",
       "      <td>2.546541</td>\n",
       "      <td>2.748511</td>\n",
       "      <td>2.738165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>GSM706002.CEL.gz</td>\n",
       "      <td>B-CELL_ALL_ETV6-RUNX1</td>\n",
       "      <td>6.692887</td>\n",
       "      <td>4.736595</td>\n",
       "      <td>4.503892</td>\n",
       "      <td>7.484208</td>\n",
       "      <td>3.137376</td>\n",
       "      <td>7.917993</td>\n",
       "      <td>3.858845</td>\n",
       "      <td>3.341846</td>\n",
       "      <td>...</td>\n",
       "      <td>3.215936</td>\n",
       "      <td>3.801296</td>\n",
       "      <td>12.292519</td>\n",
       "      <td>12.288550</td>\n",
       "      <td>3.402729</td>\n",
       "      <td>3.042387</td>\n",
       "      <td>2.965890</td>\n",
       "      <td>2.528686</td>\n",
       "      <td>2.705429</td>\n",
       "      <td>2.762513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>GSM706003.CEL.gz</td>\n",
       "      <td>B-CELL_ALL_ETV6-RUNX1</td>\n",
       "      <td>6.209500</td>\n",
       "      <td>4.566413</td>\n",
       "      <td>4.637307</td>\n",
       "      <td>7.348777</td>\n",
       "      <td>3.018984</td>\n",
       "      <td>6.423441</td>\n",
       "      <td>3.669993</td>\n",
       "      <td>3.406887</td>\n",
       "      <td>...</td>\n",
       "      <td>3.266234</td>\n",
       "      <td>3.873540</td>\n",
       "      <td>11.971540</td>\n",
       "      <td>12.035205</td>\n",
       "      <td>3.321740</td>\n",
       "      <td>3.030698</td>\n",
       "      <td>2.826285</td>\n",
       "      <td>2.573647</td>\n",
       "      <td>2.942468</td>\n",
       "      <td>2.666361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>GSM706004.CEL.gz</td>\n",
       "      <td>B-CELL_ALL_ETV6-RUNX1</td>\n",
       "      <td>6.046964</td>\n",
       "      <td>5.252467</td>\n",
       "      <td>4.420044</td>\n",
       "      <td>7.086734</td>\n",
       "      <td>2.913081</td>\n",
       "      <td>7.723025</td>\n",
       "      <td>3.474380</td>\n",
       "      <td>3.309239</td>\n",
       "      <td>...</td>\n",
       "      <td>3.150403</td>\n",
       "      <td>3.756845</td>\n",
       "      <td>11.977577</td>\n",
       "      <td>11.719864</td>\n",
       "      <td>3.541711</td>\n",
       "      <td>2.959812</td>\n",
       "      <td>2.760271</td>\n",
       "      <td>2.514172</td>\n",
       "      <td>2.811914</td>\n",
       "      <td>2.697337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>GSM706005.CEL.gz</td>\n",
       "      <td>B-CELL_ALL_ETV6-RUNX1</td>\n",
       "      <td>6.347403</td>\n",
       "      <td>4.903981</td>\n",
       "      <td>4.281019</td>\n",
       "      <td>6.989415</td>\n",
       "      <td>2.968945</td>\n",
       "      <td>7.618195</td>\n",
       "      <td>3.492828</td>\n",
       "      <td>3.266248</td>\n",
       "      <td>...</td>\n",
       "      <td>3.204594</td>\n",
       "      <td>3.918882</td>\n",
       "      <td>11.936382</td>\n",
       "      <td>12.019612</td>\n",
       "      <td>3.383822</td>\n",
       "      <td>2.864419</td>\n",
       "      <td>2.739536</td>\n",
       "      <td>2.585459</td>\n",
       "      <td>2.710848</td>\n",
       "      <td>2.769975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>GSM706007.CEL.gz</td>\n",
       "      <td>B-CELL_ALL_ETV6-RUNX1</td>\n",
       "      <td>6.687363</td>\n",
       "      <td>5.136351</td>\n",
       "      <td>4.182961</td>\n",
       "      <td>6.969701</td>\n",
       "      <td>3.006955</td>\n",
       "      <td>8.051688</td>\n",
       "      <td>3.558775</td>\n",
       "      <td>3.378041</td>\n",
       "      <td>...</td>\n",
       "      <td>3.498566</td>\n",
       "      <td>3.726283</td>\n",
       "      <td>11.750286</td>\n",
       "      <td>11.508473</td>\n",
       "      <td>3.502568</td>\n",
       "      <td>2.921487</td>\n",
       "      <td>2.942204</td>\n",
       "      <td>2.529318</td>\n",
       "      <td>2.698757</td>\n",
       "      <td>2.753662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281 rows Ã— 22285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              samples                   type  1007_s_at   1053_at    117_at  \\\n",
       "0    GSM705467.CEL.gz             B-CELL_ALL   7.409521  5.009216  4.173607   \n",
       "1    GSM705468.CEL.gz             B-CELL_ALL   7.177109  5.415108  4.426778   \n",
       "2    GSM705469.CEL.gz             B-CELL_ALL   6.564918  5.248020  4.252414   \n",
       "3    GSM705470.CEL.gz             B-CELL_ALL   6.872028  5.155963  4.388849   \n",
       "4    GSM705471.CEL.gz             B-CELL_ALL   7.402105  5.509826  4.284291   \n",
       "..                ...                    ...        ...       ...       ...   \n",
       "276  GSM706002.CEL.gz  B-CELL_ALL_ETV6-RUNX1   6.692887  4.736595  4.503892   \n",
       "277  GSM706003.CEL.gz  B-CELL_ALL_ETV6-RUNX1   6.209500  4.566413  4.637307   \n",
       "278  GSM706004.CEL.gz  B-CELL_ALL_ETV6-RUNX1   6.046964  5.252467  4.420044   \n",
       "279  GSM706005.CEL.gz  B-CELL_ALL_ETV6-RUNX1   6.347403  4.903981  4.281019   \n",
       "280  GSM706007.CEL.gz  B-CELL_ALL_ETV6-RUNX1   6.687363  5.136351  4.182961   \n",
       "\n",
       "       121_at  1255_g_at   1294_at   1316_at   1320_at  ...  \\\n",
       "0    7.315369   3.185411  7.620644  3.731541  3.471587  ...   \n",
       "1    7.550818   3.134181  7.685723  3.907953  3.650995  ...   \n",
       "2    7.175169   3.017718  7.956261  3.354557  3.302989  ...   \n",
       "3    7.365933   3.031735  7.830002  3.508926  3.412491  ...   \n",
       "4    7.214947   2.925269  7.789838  3.610425  3.362593  ...   \n",
       "..        ...        ...       ...       ...       ...  ...   \n",
       "276  7.484208   3.137376  7.917993  3.858845  3.341846  ...   \n",
       "277  7.348777   3.018984  6.423441  3.669993  3.406887  ...   \n",
       "278  7.086734   2.913081  7.723025  3.474380  3.309239  ...   \n",
       "279  6.989415   2.968945  7.618195  3.492828  3.266248  ...   \n",
       "280  6.969701   3.006955  8.051688  3.558775  3.378041  ...   \n",
       "\n",
       "     AFFX-r2-Hs28SrRNA-5_at  AFFX-r2-Hs28SrRNA-M_at  AFFX-r2-P1-cre-3_at  \\\n",
       "0                  2.968822                3.223820            11.968681   \n",
       "1                  2.982888                3.690411            12.318004   \n",
       "2                  2.897425                3.611584            11.748222   \n",
       "3                  3.024722                3.713087            12.208588   \n",
       "4                  3.259802                4.096010            11.641305   \n",
       "..                      ...                     ...                  ...   \n",
       "276                3.215936                3.801296            12.292519   \n",
       "277                3.266234                3.873540            11.971540   \n",
       "278                3.150403                3.756845            11.977577   \n",
       "279                3.204594                3.918882            11.936382   \n",
       "280                3.498566                3.726283            11.750286   \n",
       "\n",
       "     AFFX-r2-P1-cre-5_at  AFFX-ThrX-3_at  AFFX-ThrX-5_at  AFFX-ThrX-M_at  \\\n",
       "0              12.100004        3.457507        2.967138        2.790814   \n",
       "1              12.486741        3.396412        3.109629        2.856499   \n",
       "2              11.807578        3.265585        3.057079        2.724642   \n",
       "3              12.148604        3.175092        2.896168        2.798296   \n",
       "4              11.713311        3.507025        3.119397        2.761294   \n",
       "..                   ...             ...             ...             ...   \n",
       "276            12.288550        3.402729        3.042387        2.965890   \n",
       "277            12.035205        3.321740        3.030698        2.826285   \n",
       "278            11.719864        3.541711        2.959812        2.760271   \n",
       "279            12.019612        3.383822        2.864419        2.739536   \n",
       "280            11.508473        3.502568        2.921487        2.942204   \n",
       "\n",
       "     AFFX-TrpnX-3_at  AFFX-TrpnX-5_at  AFFX-TrpnX-M_at  \n",
       "0           2.563377         2.860505         2.608381  \n",
       "1           2.603355         2.908509         2.634063  \n",
       "2           2.440532         2.626871         2.673293  \n",
       "3           2.522343         2.762835         2.624163  \n",
       "4           2.546541         2.748511         2.738165  \n",
       "..               ...              ...              ...  \n",
       "276         2.528686         2.705429         2.762513  \n",
       "277         2.573647         2.942468         2.666361  \n",
       "278         2.514172         2.811914         2.697337  \n",
       "279         2.585459         2.710848         2.769975  \n",
       "280         2.529318         2.698757         2.753662  \n",
       "\n",
       "[281 rows x 22285 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First we open our raw data to check what the dataframe looks like\n",
    "df = pd.read_csv('Leukemia_GSE28497.csv')\n",
    "#df = pd.read_csv('Data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8baa24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see, there are 281 samples and 22285 features, with 7 classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "121b2daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-CELL_ALL' 'B-CELL_ALL_TCF3-PBX1' 'B-CELL_ALL_HYPERDIP'\n",
      " 'B-CELL_ALL_HYPO' 'B-CELL_ALL_MLL' 'B-CELL_ALL_T-ALL'\n",
      " 'B-CELL_ALL_ETV6-RUNX1']\n"
     ]
    }
   ],
   "source": [
    "#We see that the class names are in the second column, so we print all the unique classes in our dataset.\n",
    "\n",
    "unique_terms = df['type'].unique()\n",
    "print(unique_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac75903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         7.40952068 5.00921625 ... 2.56337737 2.86050524 2.60838058]\n",
      " [1.         7.17710864 5.41510846 ... 2.60335476 2.90850944 2.63406266]\n",
      " [1.         6.56491786 5.24801999 ... 2.44053215 2.626871   2.67329262]\n",
      " ...\n",
      " [7.         6.04696407 5.25246707 ... 2.51417214 2.81191377 2.69733706]\n",
      " [7.         6.34740294 4.90398114 ... 2.58545891 2.71084814 2.76997468]\n",
      " [7.         6.68736339 5.1363513  ... 2.52931788 2.69875691 2.7536624 ]]\n",
      "\n",
      "The shape of the data is: (281, 22284)\n"
     ]
    }
   ],
   "source": [
    "#To simplify our classification problem, we replace each unique class (type) with its corresponding index from 1 to 7\n",
    "\n",
    "#Create a dictionary to simplify the replacement step\n",
    "\n",
    "map_dict = {'B-CELL_ALL':1, 'B-CELL_ALL_TCF3-PBX1': 2, 'B-CELL_ALL_HYPERDIP': 3,\n",
    " 'B-CELL_ALL_HYPO': 4, 'B-CELL_ALL_MLL': 5, 'B-CELL_ALL_T-ALL': 6,'B-CELL_ALL_ETV6-RUNX1': 7}\n",
    "\n",
    "#Replace unique terms with their respective values\n",
    "\n",
    "df['type'] = df['type'].replace(map_dict)\n",
    "\n",
    "#View the updated DataFrame\n",
    "\n",
    "new_df = df.iloc[:, 1:]\n",
    "\n",
    "arr = new_df.values\n",
    "\n",
    "print(arr)\n",
    "print()\n",
    "print('The shape of the data is:' ,arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b091102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, the column 1 represents the leukemia subclass from 1-7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb300383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The labels in our entire dataset are: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6.\n",
      " 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6.\n",
      " 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7.\n",
      " 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7.\n",
      " 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7.]\n",
      "\n",
      "The shape of the label column is: (281,)\n"
     ]
    }
   ],
   "source": [
    "#Next, we print out the labels in our dataset to check how many times each label is present in the data\n",
    "\n",
    "first_column = arr[:, 0]\n",
    "print('The labels in our entire dataset are:',first_column)\n",
    "print()\n",
    "print('The shape of the label column is:',first_column.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e4c0277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we know what our data looks like, we can start working on implementing the kNN algorithm for our classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89e2ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kNN is based on a distance metric, and for our implementation we use euclidean distance. We first a function for the same.\n",
    "\n",
    "#We define a function for euclidean distance for distance between two corresponding gene points\n",
    "def euclidean_distance(x1, x2):\n",
    "    \n",
    "    dist = np.sqrt(np.sum((x1 - x2)**2))\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4d3fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make the implementation of the kNN easy, we build a class which runs the kNN for us. The class has three methods, init, sit and predict \n",
    "\n",
    "class KNN:\n",
    "    \n",
    "    #init will set the k value for our kNN run.\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "    \n",
    "    #fit will fit the training data along with its corresponding labels\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    #Predict will run the kNN on test data, and then return the predicted labels for it, after running the kNN algorthm on it \n",
    "    def predict(self, X):\n",
    "        \n",
    "        predicted_labels = []\n",
    "        \n",
    "        for x in X:\n",
    "            \n",
    "            #Calculate the distances between the new data point and each point in the training data\n",
    "            distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "            #print(distances)\n",
    "            \n",
    "            #Select the k nearest neighbors\n",
    "            k_indices = np.argsort(distances)[:self.k]\n",
    "            k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "            #print(k_nearest_labels)\n",
    "            \n",
    "            #Count the number of neighbors in each class\n",
    "            counts = np.bincount(k_nearest_labels)\n",
    "            #print(counts)\n",
    "            \n",
    "            # Assign the new data point to the class with the highest number of neighbors\n",
    "            predicted_labels.append(np.argmax(counts))\n",
    "\n",
    "        return np.array(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d935bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the validation of our model, we have also built functions which measure accuracy, recall, precision and the F1-score. \n",
    "#Each of these functions can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54949da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute accuracy calculates the accuracy of the true labels against predicted labels.\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    n_correct = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            n_correct += 1\n",
    "    accuracy = n_correct / len(y_true) #Number of correct entries / total entries \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c0b4beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute precision calculates the precision of the labels \n",
    "def compute_precision(y_true, y_pred, class_label):\n",
    "    TP = 0 #Initialize true positive to 0\n",
    "    FP = 0 #Initialize false positive to 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_pred[i] == class_label:\n",
    "            if y_true[i] == class_label:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "    if TP + FP == 0:\n",
    "        precision = 0.0\n",
    "    else:\n",
    "        precision = TP / (TP + FP)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a12fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute recall calculates the recall of the labels\n",
    "def compute_recall(y_true, y_pred, class_label):\n",
    "    TP = 0 #Initialize true positive to 0\n",
    "    FN = 0 #Initialize false negative to 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == class_label:\n",
    "            if y_pred[i] == class_label:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "    if TP + FN == 0:\n",
    "        recall = 0.0\n",
    "    else:\n",
    "        recall = TP / (TP + FN)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5151e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute f1 score calculates the f1 score of the labels using the precision and recall functions\n",
    "def compute_f1_score(y_true, y_pred, class_label):\n",
    "    precision = compute_precision(y_true, y_pred, class_label)\n",
    "    recall = compute_recall(y_true, y_pred, class_label)\n",
    "    if precision + recall == 0:\n",
    "        f1_score = 0.0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a94dd56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can implement the kNN algortihm on thedata to build a classifier. Before we do so, we do 10 fold cross validation since we have fairly fewer samples. \n",
    "#The implementation of the cross validation can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c86ad65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1\n",
      "The accuracy of the training classification is: 85.71 %\n",
      "The accuracy of the testing classification is: 96.55 %\n",
      "\n",
      "For fold 2\n",
      "The accuracy of the training classification is: 85.38 %\n",
      "The accuracy of the testing classification is: 82.14 %\n",
      "\n",
      "For fold 3\n",
      "The accuracy of the training classification is: 86.56 %\n",
      "The accuracy of the testing classification is: 78.57 %\n",
      "\n",
      "For fold 4\n",
      "The accuracy of the training classification is: 84.98 %\n",
      "The accuracy of the testing classification is: 89.29 %\n",
      "\n",
      "For fold 5\n",
      "The accuracy of the training classification is: 86.56 %\n",
      "The accuracy of the testing classification is: 71.43 %\n",
      "\n",
      "For fold 6\n",
      "The accuracy of the training classification is: 86.96 %\n",
      "The accuracy of the testing classification is: 75.00 %\n",
      "\n",
      "For fold 7\n",
      "The accuracy of the training classification is: 84.19 %\n",
      "The accuracy of the testing classification is: 85.71 %\n",
      "\n",
      "For fold 8\n",
      "The accuracy of the training classification is: 86.56 %\n",
      "The accuracy of the testing classification is: 85.71 %\n",
      "\n",
      "For fold 9\n",
      "The accuracy of the training classification is: 84.58 %\n",
      "The accuracy of the testing classification is: 85.71 %\n",
      "\n",
      "For fold 10\n",
      "The accuracy of the training classification is: 84.98 %\n",
      "The accuracy of the testing classification is: 78.57 %\n",
      "\n",
      "The mean accuracy of the training classification is: 85.65 %\n",
      "The mean accuracy of the testing classification is: 82.87 %\n"
     ]
    }
   ],
   "source": [
    "# k-fold cross-validation\n",
    "\n",
    "# First we need to define the number of folds\n",
    "k = 10\n",
    "\n",
    "# Shuffle the dataset randomly\n",
    "np.random.seed(4)\n",
    "indices = np.random.permutation(len(arr))\n",
    "\n",
    "# Split the dataset into k groups\n",
    "folds = np.array_split(indices, k)\n",
    "\n",
    "# Initialize the lists to store accuracy for each fold\n",
    "acc_list_train = []\n",
    "acc_list_test = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('For fold', i+1)\n",
    "    \n",
    "    # Create the training and testing datasets for the current fold\n",
    "    test_indices = folds[i]\n",
    "    train_indices = np.concatenate([folds[j] for j in range(k) if j != i])\n",
    "    \n",
    "    X_train = arr[train_indices, :]\n",
    "    y_train = first_column[train_indices]\n",
    "    X_test = arr[test_indices, :]\n",
    "    y_test = first_column[test_indices]\n",
    "    \n",
    "    # Create an instance of the KNN class with k ranging from 1-10\n",
    "    knn = KNN(k)\n",
    "\n",
    "    # Fit the KNN classifier on the training data and labels\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels for the testing data\n",
    "    y_pred = knn.predict(X_test)\n",
    "    y_pred_train = knn.predict(X_train)\n",
    "\n",
    "    # Compute and store the accuracy for the current fold\n",
    "    accuracy_train = compute_accuracy(y_train,y_pred_train)\n",
    "    accuracy_test = compute_accuracy(y_test,y_pred)\n",
    "    acc_list_train.append(accuracy_train)\n",
    "    acc_list_test.append(accuracy_test)\n",
    "    \n",
    "    print(\"The accuracy of the training classification is: {:.2f} %\".format((accuracy_train)*100))\n",
    "    print(\"The accuracy of the testing classification is: {:.2f} %\".format((accuracy_test)*100))\n",
    "    print()\n",
    "    \n",
    "print(\"The mean accuracy of the training classification is: {:.2f} %\".format(np.mean(acc_list_train)*100))\n",
    "print(\"The mean accuracy of the testing classification is: {:.2f} %\".format(np.mean(acc_list_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7c02d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have the accuracy from the cross validation, we can test our model to see how well our classifier performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d4d3571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1 neighbours, the results are as shown below:\n",
      "\n",
      "The test classes are: [7. 1. 5. 6. 7. 3. 2. 2. 3. 1. 2. 1. 1. 1. 2. 3. 1. 5. 1. 7. 3. 7. 7. 7.\n",
      " 1. 7. 1. 3. 1. 7. 5. 7. 6. 6. 5. 1. 1. 7. 7. 1. 4. 6. 7. 4. 3. 4. 3. 2.\n",
      " 6. 3. 7. 1. 6. 1. 3. 7. 3.]\n",
      "The predicted classes are: [7 3 5 6 7 3 2 2 1 1 2 3 1 1 2 3 1 5 1 7 3 7 7 7 1 4 1 4 1 7 5 7 6 6 5 1 1\n",
      " 7 1 4 3 6 7 4 3 1 3 2 6 3 7 4 6 1 3 7 1]\n",
      "\n",
      "The accuracy of the training classification is: 100.00 %\n",
      "The accuracy of the testing classification is: 80.70 %\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "For 2 neighbours, the results are as shown below:\n",
      "\n",
      "The test classes are: [7. 1. 5. 6. 7. 3. 2. 2. 3. 1. 2. 1. 1. 1. 2. 3. 1. 5. 1. 7. 3. 7. 7. 7.\n",
      " 1. 7. 1. 3. 1. 7. 5. 7. 6. 6. 5. 1. 1. 7. 7. 1. 4. 6. 7. 4. 3. 4. 3. 2.\n",
      " 6. 3. 7. 1. 6. 1. 3. 7. 3.]\n",
      "The predicted classes are: [7 1 5 6 7 3 2 2 1 1 2 1 1 1 2 3 1 5 1 7 3 7 7 7 1 4 1 1 1 7 5 7 6 6 5 1 1\n",
      " 7 1 1 1 6 7 4 1 1 3 2 6 1 7 4 6 1 3 7 1]\n",
      "\n",
      "The accuracy of the training classification is: 93.30 %\n",
      "The accuracy of the testing classification is: 82.46 %\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "For 3 neighbours, the results are as shown below:\n",
      "\n",
      "The test classes are: [7. 1. 5. 6. 7. 3. 2. 2. 3. 1. 2. 1. 1. 1. 2. 3. 1. 5. 1. 7. 3. 7. 7. 7.\n",
      " 1. 7. 1. 3. 1. 7. 5. 7. 6. 6. 5. 1. 1. 7. 7. 1. 4. 6. 7. 4. 3. 4. 3. 2.\n",
      " 6. 3. 7. 1. 6. 1. 3. 7. 3.]\n",
      "The predicted classes are: [7 3 5 6 7 3 2 2 1 1 2 3 1 1 2 3 3 5 1 7 3 7 7 7 1 7 1 1 1 7 5 7 6 6 5 1 1\n",
      " 7 1 1 1 6 7 4 3 1 3 2 6 1 7 4 6 1 3 7 3]\n",
      "\n",
      "The accuracy of the training classification is: 90.62 %\n",
      "The accuracy of the testing classification is: 82.46 %\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "For 4 neighbours, the results are as shown below:\n",
      "\n",
      "The test classes are: [7. 1. 5. 6. 7. 3. 2. 2. 3. 1. 2. 1. 1. 1. 2. 3. 1. 5. 1. 7. 3. 7. 7. 7.\n",
      " 1. 7. 1. 3. 1. 7. 5. 7. 6. 6. 5. 1. 1. 7. 7. 1. 4. 6. 7. 4. 3. 4. 3. 2.\n",
      " 6. 3. 7. 1. 6. 1. 3. 7. 3.]\n",
      "The predicted classes are: [7 3 5 6 7 3 2 2 1 1 2 1 1 1 2 3 3 3 1 7 3 7 7 7 1 7 1 1 1 7 5 7 6 6 5 1 1\n",
      " 7 1 1 7 6 7 1 3 1 3 2 6 3 7 3 6 1 3 7 3]\n",
      "\n",
      "The accuracy of the training classification is: 88.39 %\n",
      "The accuracy of the testing classification is: 82.46 %\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "For 5 neighbours, the results are as shown below:\n",
      "\n",
      "The test classes are: [7. 1. 5. 6. 7. 3. 2. 2. 3. 1. 2. 1. 1. 1. 2. 3. 1. 5. 1. 7. 3. 7. 7. 7.\n",
      " 1. 7. 1. 3. 1. 7. 5. 7. 6. 6. 5. 1. 1. 7. 7. 1. 4. 6. 7. 4. 3. 4. 3. 2.\n",
      " 6. 3. 7. 1. 6. 1. 3. 7. 3.]\n",
      "The predicted classes are: [7 3 5 6 7 3 2 2 1 1 2 3 1 1 2 3 3 3 1 7 1 7 7 7 1 7 1 1 1 7 5 7 6 6 5 1 1\n",
      " 7 1 1 7 6 7 1 3 1 3 2 6 1 7 3 6 1 3 7 3]\n",
      "\n",
      "The accuracy of the training classification is: 89.29 %\n",
      "The accuracy of the testing classification is: 77.19 %\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "For 6 neighbours, the results are as shown below:\n",
      "\n",
      "The test classes are: [7. 1. 5. 6. 7. 3. 2. 2. 3. 1. 2. 1. 1. 1. 2. 3. 1. 5. 1. 7. 3. 7. 7. 7.\n",
      " 1. 7. 1. 3. 1. 7. 5. 7. 6. 6. 5. 1. 1. 7. 7. 1. 4. 6. 7. 4. 3. 4. 3. 2.\n",
      " 6. 3. 7. 1. 6. 1. 3. 7. 3.]\n",
      "The predicted classes are: [7 3 5 6 7 3 2 2 1 4 2 1 1 1 2 3 3 3 1 7 3 7 7 7 1 7 1 3 1 7 5 7 6 6 5 1 1\n",
      " 7 1 1 7 6 7 1 3 1 3 2 6 3 7 1 6 1 3 7 3]\n",
      "\n",
      "The accuracy of the training classification is: 88.84 %\n",
      "The accuracy of the testing classification is: 84.21 %\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "For 7 neighbours, the results are as shown below:\n",
      "\n",
      "The test classes are: [7. 1. 5. 6. 7. 3. 2. 2. 3. 1. 2. 1. 1. 1. 2. 3. 1. 5. 1. 7. 3. 7. 7. 7.\n",
      " 1. 7. 1. 3. 1. 7. 5. 7. 6. 6. 5. 1. 1. 7. 7. 1. 4. 6. 7. 4. 3. 4. 3. 2.\n",
      " 6. 3. 7. 1. 6. 1. 3. 7. 3.]\n",
      "The predicted classes are: [7 3 5 6 7 3 2 2 1 3 2 1 1 1 2 3 3 3 1 7 3 7 7 7 1 7 1 3 1 7 5 7 6 6 5 1 1\n",
      " 7 7 1 7 6 7 1 3 1 3 2 6 3 7 1 6 1 3 7 3]\n",
      "\n",
      "The accuracy of the training classification is: 86.61 %\n",
      "The accuracy of the testing classification is: 85.96 %\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "For 8 neighbours, the results are as shown below:\n",
      "\n",
      "The test classes are: [7. 1. 5. 6. 7. 3. 2. 2. 3. 1. 2. 1. 1. 1. 2. 3. 1. 5. 1. 7. 3. 7. 7. 7.\n",
      " 1. 7. 1. 3. 1. 7. 5. 7. 6. 6. 5. 1. 1. 7. 7. 1. 4. 6. 7. 4. 3. 4. 3. 2.\n",
      " 6. 3. 7. 1. 6. 1. 3. 7. 3.]\n",
      "The predicted classes are: [7 3 5 6 7 3 2 2 1 1 2 1 1 1 2 3 3 3 1 7 3 7 7 7 1 7 1 1 1 7 5 7 6 6 5 1 1\n",
      " 7 1 1 1 6 7 1 3 1 3 2 6 3 7 1 6 1 3 7 3]\n",
      "\n",
      "The accuracy of the training classification is: 85.71 %\n",
      "The accuracy of the testing classification is: 84.21 %\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "For 9 neighbours, the results are as shown below:\n",
      "\n",
      "The test classes are: [7. 1. 5. 6. 7. 3. 2. 2. 3. 1. 2. 1. 1. 1. 2. 3. 1. 5. 1. 7. 3. 7. 7. 7.\n",
      " 1. 7. 1. 3. 1. 7. 5. 7. 6. 6. 5. 1. 1. 7. 7. 1. 4. 6. 7. 4. 3. 4. 3. 2.\n",
      " 6. 3. 7. 1. 6. 1. 3. 7. 3.]\n",
      "The predicted classes are: [7 3 1 6 7 3 2 2 1 3 2 3 1 1 2 3 3 3 1 7 3 7 7 7 1 7 1 3 1 7 5 7 6 6 5 1 1\n",
      " 7 7 1 1 6 7 1 3 1 3 2 6 3 7 1 6 1 3 7 3]\n",
      "\n",
      "The accuracy of the training classification is: 85.71 %\n",
      "The accuracy of the testing classification is: 82.46 %\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "For 10 neighbours, the results are as shown below:\n",
      "\n",
      "The test classes are: [7. 1. 5. 6. 7. 3. 2. 2. 3. 1. 2. 1. 1. 1. 2. 3. 1. 5. 1. 7. 3. 7. 7. 7.\n",
      " 1. 7. 1. 3. 1. 7. 5. 7. 6. 6. 5. 1. 1. 7. 7. 1. 4. 6. 7. 4. 3. 4. 3. 2.\n",
      " 6. 3. 7. 1. 6. 1. 3. 7. 3.]\n",
      "The predicted classes are: [7 3 1 6 7 3 2 2 1 3 2 1 1 1 2 3 3 3 1 7 3 7 7 7 1 7 1 3 1 7 5 7 6 6 5 1 1\n",
      " 7 7 1 7 6 7 1 3 1 3 2 6 3 7 1 6 1 3 7 3]\n",
      "\n",
      "The accuracy of the training classification is: 87.05 %\n",
      "The accuracy of the testing classification is: 84.21 %\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "For 11 neighbours, the results are as shown below:\n",
      "\n",
      "The test classes are: [7. 1. 5. 6. 7. 3. 2. 2. 3. 1. 2. 1. 1. 1. 2. 3. 1. 5. 1. 7. 3. 7. 7. 7.\n",
      " 1. 7. 1. 3. 1. 7. 5. 7. 6. 6. 5. 1. 1. 7. 7. 1. 4. 6. 7. 4. 3. 4. 3. 2.\n",
      " 6. 3. 7. 1. 6. 1. 3. 7. 3.]\n",
      "The predicted classes are: [7 3 1 6 7 3 2 2 1 3 2 3 1 1 2 3 3 3 1 7 3 7 7 7 1 7 1 3 1 7 5 7 6 6 5 1 1\n",
      " 7 7 1 1 6 7 1 3 1 3 2 6 3 7 1 6 1 3 7 3]\n",
      "\n",
      "The accuracy of the training classification is: 85.71 %\n",
      "The accuracy of the testing classification is: 82.46 %\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "For 12 neighbours, the results are as shown below:\n",
      "\n",
      "The test classes are: [7. 1. 5. 6. 7. 3. 2. 2. 3. 1. 2. 1. 1. 1. 2. 3. 1. 5. 1. 7. 3. 7. 7. 7.\n",
      " 1. 7. 1. 3. 1. 7. 5. 7. 6. 6. 5. 1. 1. 7. 7. 1. 4. 6. 7. 4. 3. 4. 3. 2.\n",
      " 6. 3. 7. 1. 6. 1. 3. 7. 3.]\n",
      "The predicted classes are: [7 3 1 6 7 3 2 2 1 3 2 3 1 1 2 3 3 3 1 7 3 7 7 7 1 7 1 3 1 7 5 7 6 6 5 1 1\n",
      " 7 7 1 1 6 7 1 3 1 3 2 6 3 7 1 6 1 3 7 3]\n",
      "\n",
      "The accuracy of the training classification is: 85.71 %\n",
      "The accuracy of the testing classification is: 82.46 %\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "For 13 neighbours, the results are as shown below:\n",
      "\n",
      "The test classes are: [7. 1. 5. 6. 7. 3. 2. 2. 3. 1. 2. 1. 1. 1. 2. 3. 1. 5. 1. 7. 3. 7. 7. 7.\n",
      " 1. 7. 1. 3. 1. 7. 5. 7. 6. 6. 5. 1. 1. 7. 7. 1. 4. 6. 7. 4. 3. 4. 3. 2.\n",
      " 6. 3. 7. 1. 6. 1. 3. 7. 3.]\n",
      "The predicted classes are: [7 3 1 6 7 3 2 2 1 3 2 3 1 1 2 3 3 1 1 7 3 7 7 7 1 7 1 1 1 7 5 7 6 6 5 1 1\n",
      " 7 7 1 1 6 7 1 3 1 3 2 6 3 7 1 6 1 3 7 3]\n",
      "\n",
      "The accuracy of the training classification is: 84.38 %\n",
      "The accuracy of the testing classification is: 80.70 %\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "For 14 neighbours, the results are as shown below:\n",
      "\n",
      "The test classes are: [7. 1. 5. 6. 7. 3. 2. 2. 3. 1. 2. 1. 1. 1. 2. 3. 1. 5. 1. 7. 3. 7. 7. 7.\n",
      " 1. 7. 1. 3. 1. 7. 5. 7. 6. 6. 5. 1. 1. 7. 7. 1. 4. 6. 7. 4. 3. 4. 3. 2.\n",
      " 6. 3. 7. 1. 6. 1. 3. 7. 3.]\n",
      "The predicted classes are: [7 3 1 6 7 3 2 2 1 3 2 3 1 1 2 3 3 3 1 7 3 7 7 7 1 7 1 1 1 7 5 7 6 6 5 1 1\n",
      " 7 7 1 1 6 7 1 3 1 3 2 6 3 7 1 6 1 3 7 3]\n",
      "\n",
      "The accuracy of the training classification is: 84.82 %\n",
      "The accuracy of the testing classification is: 80.70 %\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "For 15 neighbours, the results are as shown below:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test classes are: [7. 1. 5. 6. 7. 3. 2. 2. 3. 1. 2. 1. 1. 1. 2. 3. 1. 5. 1. 7. 3. 7. 7. 7.\n",
      " 1. 7. 1. 3. 1. 7. 5. 7. 6. 6. 5. 1. 1. 7. 7. 1. 4. 6. 7. 4. 3. 4. 3. 2.\n",
      " 6. 3. 7. 1. 6. 1. 3. 7. 3.]\n",
      "The predicted classes are: [7 3 1 6 7 3 2 2 1 3 2 3 1 1 2 3 3 3 1 7 3 7 7 7 1 7 1 1 1 7 5 7 6 6 5 1 1\n",
      " 7 7 1 1 6 7 1 3 1 3 2 6 3 7 1 6 1 3 7 3]\n",
      "\n",
      "The accuracy of the training classification is: 82.59 %\n",
      "The accuracy of the testing classification is: 80.70 %\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the dataset randomly\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(arr))\n",
    "# print(indices)\n",
    "\n",
    "#We split the model into an 80-20 set where 80% of the data is used as a training dataset. \n",
    "#Here, 20% of the model is used as a test dataset.\n",
    "X_train = arr[indices[:int(0.8*len(arr))], :]\n",
    "\n",
    "#print(X_train.shape)\n",
    "#print(X_train)\n",
    "\n",
    "y_train = first_column[indices[:int(0.8*len(arr))]]\n",
    "\n",
    "#print(y_train.shape)\n",
    "#print(y_train)\n",
    "\n",
    "X_test = arr[indices[int(0.8*len(arr)):], :]\n",
    "\n",
    "#print(X_test.shape)\n",
    "#print(X_test)\n",
    "\n",
    "y_test = first_column[indices[int(0.8*len(arr)):]]\n",
    "\n",
    "#print(y_test.shape)\n",
    "#print(y_test)\n",
    "\n",
    "# Initialize the lists to store accuracy for training and testing accuracy\n",
    "k_list = []\n",
    "acc_list_test = []\n",
    "acc_list_train = []\n",
    "\n",
    "#Range over 15 nearest neighbour sizes, to determine which k value gives the highest accuracy.\n",
    "for k in range(1,16):\n",
    "    \n",
    "    k_list.append(k)\n",
    "    \n",
    "    print('For',k,'neighbours, the results are as shown below:') \n",
    "    print()\n",
    "\n",
    "    # Create an instance of the KNN class with k ranging from 1-15\n",
    "    knn = KNN(k)\n",
    "\n",
    "    # Fit the KNN classifier on the training data and labels\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels for the testing data\n",
    "    y_pred = knn.predict(X_test)\n",
    "    y_pred_train = knn.predict(X_train)\n",
    "\n",
    "    print('The test classes are:', y_test)\n",
    "    print('The predicted classes are:',y_pred)\n",
    "\n",
    "    print()\n",
    "    accuracy = compute_accuracy(y_test,y_pred)\n",
    "    accuracy_train = compute_accuracy(y_train,y_pred_train)\n",
    "    \n",
    "    print(\"The accuracy of the training classification is: {:.2f} %\".format((accuracy_train)*100))\n",
    "    print(\"The accuracy of the testing classification is: {:.2f} %\".format((accuracy)*100))\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------------------------------')\n",
    "    print()\n",
    "    \n",
    "    acc_list_test.append(accuracy)\n",
    "    acc_list_train.append(accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31129119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we want to identofy what the best value of k is. We select this based on the k value which gives the highest test accuracy. \n",
    "#To determine this we plot the test accuracy vs k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7273ed9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The plot of accuracy of test data against cluster size\n",
    "plt.figure()\n",
    "plt.scatter(k_list, acc_list_test, marker='o')\n",
    "plt.plot(k_list, acc_list_test, linestyle='-', color='b', )\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlim(0, 16, 1)\n",
    "plt.axvline(x=7, color='b', linestyle='--',linewidth = '0.5') # vertical line at x=7\n",
    "plt.axhline(y=acc_list_test[k_list.index(7)], color='b', linestyle='--',linewidth = '0.5') # horizontal line at y=accuracy value for k=7\n",
    "plt.ylim(0.68, 0.88)\n",
    "plt.title('Accuracy vs k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81cd58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see, the k=7 has the highest accuracy of nearly 86%. \n",
    "#For our classification, we will use k = 7 \n",
    "\n",
    "#Now we try to carry out the classification for the test samples for k=7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88c03417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 7 neighbours, the results are as shown below:\n",
      "\n",
      "The test classes are: [7. 1. 5. 6. 7. 3. 2. 2. 3. 1. 2. 1. 1. 1. 2. 3. 1. 5. 1. 7. 3. 7. 7. 7.\n",
      " 1. 7. 1. 3. 1. 7. 5. 7. 6. 6. 5. 1. 1. 7. 7. 1. 4. 6. 7. 4. 3. 4. 3. 2.\n",
      " 6. 3. 7. 1. 6. 1. 3. 7. 3.]\n",
      "The predicted classes are: [7 3 5 6 7 3 2 2 1 3 2 1 1 1 2 3 3 3 1 7 3 7 7 7 1 7 1 3 1 7 5 7 6 6 5 1 1\n",
      " 7 7 1 7 6 7 1 3 1 3 2 6 3 7 1 6 1 3 7 3]\n",
      "\n",
      "The accuracy of the training classification is: 86.61 %\n",
      "The accuracy of the testing classification is: 85.96 %\n",
      "\n",
      "Precision of class 1 is 0.8000\n",
      "Recall of class 1 is 0.8000\n",
      "F1 score of class 1 is 0.8000\n",
      "\n",
      "Precision of class 2 is 1.0000\n",
      "Recall of class 2 is 1.0000\n",
      "F1 score of class 2 is 1.0000\n",
      "\n",
      "Precision of class 3 is 0.6923\n",
      "Recall of class 3 is 0.9000\n",
      "F1 score of class 3 is 0.7826\n",
      "\n",
      "Precision of class 4 is 0.0000\n",
      "Recall of class 4 is 0.0000\n",
      "F1 score of class 4 is 0.0000\n",
      "\n",
      "Precision of class 5 is 1.0000\n",
      "Recall of class 5 is 0.7500\n",
      "F1 score of class 5 is 0.8571\n",
      "\n",
      "Precision of class 6 is 1.0000\n",
      "Recall of class 6 is 1.0000\n",
      "F1 score of class 6 is 1.0000\n",
      "\n",
      "Precision of class 7 is 0.9333\n",
      "Recall of class 7 is 1.0000\n",
      "F1 score of class 7 is 0.9655\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We test for 7 nearest neighbours\n",
    "k = 7 \n",
    "    \n",
    "print('For',k,'neighbours, the results are as shown below:') \n",
    "print()\n",
    "\n",
    "# Create an instance of the KNN class with k=7\n",
    "knn = KNN(k)\n",
    "\n",
    "# Fit the KNN classifier on the training data and labels\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the testing data\n",
    "y_pred = knn.predict(X_test)\n",
    "y_pred_train = knn.predict(X_train)\n",
    "\n",
    "\n",
    "print('The test classes are:', y_test)\n",
    "print('The predicted classes are:',y_pred)\n",
    "\n",
    "print()\n",
    "accuracy = compute_accuracy(y_test,y_pred)\n",
    "accuracy_train = compute_accuracy(y_train,y_pred_train)\n",
    "    \n",
    "print(\"The accuracy of the training classification is: {:.2f} %\".format((accuracy_train)*100))\n",
    "print(\"The accuracy of the testing classification is: {:.2f} %\".format((accuracy)*100))\n",
    "acc_list_test.append(accuracy)\n",
    "acc_list_train.append(accuracy_train)\n",
    "print()\n",
    "\n",
    "#We also print the confusion matrix, as this will help us understand the precision, recall and f1 score of the model.\n",
    "disp = ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap = 'bone')\n",
    "\n",
    "#We print each of these parameters for each class from 1 to 7\n",
    "for i in range(1,8):\n",
    "    precision = compute_precision(y_test, y_pred, class_label=i)\n",
    "\n",
    "    # Print the precision\n",
    "    print('Precision of class', i, 'is {:.4f}'.format(precision))\n",
    "    recall = compute_recall(y_test, y_pred, class_label=i)\n",
    "\n",
    "    # Print the recall\n",
    "    print('Recall of class',i,'is {:.4f}'.format(recall))\n",
    "\n",
    "    f1_score = compute_f1_score(y_test, y_pred, class_label=i)\n",
    "\n",
    "    # Print the precision\n",
    "    print('F1 score of class',i,'is {:.4f}'.format(f1_score))\n",
    "        \n",
    "    print()\n",
    "print('------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "617dd05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see, we are able to obtain the confusion matrix for the 7 classes of interest in our dataset. We also have the precion recall and f1 score of each class\n",
    "# We also have the overall accuracy of the kNN model. \n",
    "# A detailed explanation of the results can be found in the report submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a77ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
